# ğŸš€ QUICK START GUIDE - Private AI Assistant

## âš¡ Get Started in 3 Minutes

### Step 1: Install (30 seconds)
```bash
cd /workspaces/Pro-AI
python -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Step 2: Configure (1 minute)
```bash
# Copy template
cp .env.example .env

# Open .env and add API keys (optional - Ollama works without)
# OPENAI_API_KEY=your-key
# ANTHROPIC_API_KEY=your-key
# GOOGLE_API_KEY=your-key
```

### Step 3: Run (30 seconds)
```bash
python main.py
```

### Step 4: Open Browser
Visit: **http://localhost:8000**

---

## ğŸ¯ First Time Using?

1. **Choose a Model**
   - OpenAI: Requires API key, most capable
   - Anthropic: Requires API key, good reasoning
   - Google: Requires API key, good for long text
   - Ollama: No API key, free & private (requires Ollama server)

2. **Adjust Settings**
   - Temperature: 0.0 (focused) to 2.0 (creative)
   - Max Tokens: 100-4000 (higher = longer responses)

3. **Send a Message**
   - Type in the text box
   - Click Send or press Shift+Enter
   - Watch the response appear!

4. **Continue Chatting**
   - Context is preserved automatically
   - History saved in your browser
   - Clear chat anytime with the Clear button

---

## ğŸ“ Where Everything Is

| Component | Location | Purpose |
|-----------|----------|---------|
| Web UI | `http://localhost:8000` | Chat interface |
| API Docs | `http://localhost:8000/docs` | API reference |
| Config | `.env` | API keys & settings |
| Backend | `src/` | Python code |
| Frontend | `ui/` | HTML/CSS/JS |
| Docs | `README.md` | Full documentation |

---

## ğŸ”‘ Need API Keys?

### OpenAI
1. Go to https://platform.openai.com/api-keys
2. Create new secret key
3. Copy to `.env`: `OPENAI_API_KEY=sk-...`

### Anthropic
1. Go to https://console.anthropic.com
2. Get API key
3. Copy to `.env`: `ANTHROPIC_API_KEY=sk-ant-...`

### Google Gemini
1. Go to https://ai.google.dev
2. Create API key
3. Copy to `.env`: `GOOGLE_API_KEY=...`

### Ollama (Free & Local)
1. Install from https://ollama.ai
2. Run: `ollama serve`
3. In another terminal: `ollama pull llama2`
4. No API key needed!

---

## ğŸ› Troubleshooting

### "Port already in use"
```bash
# Use different port
API_PORT=9000 python main.py
```

### "ModuleNotFoundError"
```bash
# Make sure you're in the venv
source venv/bin/activate
# And installed requirements
pip install -r requirements.txt
```

### "API key not working"
- Check `.env` file exists in project root
- Verify key is correctly copied (no extra spaces)
- Make sure key has proper permissions on the service

### "Can't connect to Ollama"
```bash
# Make sure Ollama server is running
ollama serve

# Check URL in .env
OLLAMA_BASE_URL=http://localhost:11434
```

---

## ğŸ“š Next Steps

### Learn the API
```bash
# Read the comprehensive guide
cat API_USAGE_GUIDE.md

# Or visit interactive docs
http://localhost:8000/docs
```

### Test the Backend
```bash
# In one terminal
python main.py

# In another
python test_api.py
```

### Explore the Code
```bash
# Main entry point
cat main.py

# Backend structure
ls -la src/

# See project docs
python PROJECT_DOCUMENTATION.py
```

### Build on It
- Add new endpoints in `src/backend/routes/`
- Implement tools in `src/tools/`
- Extend memory to database
- Add user authentication
- Deploy to cloud

---

## ğŸ’ª Full Documentation

- **README.md** - Overview and setup
- **API_USAGE_GUIDE.md** - API reference with examples
- **QUICK_REFERENCE.md** - Quick lookup
- **FINAL_SUMMARY.md** - Complete project summary
- **ARCHITECTURE.md** - System design
- **PROJECT_DOCUMENTATION.py** - Deep technical docs

---

## âœ¨ Features at a Glance

âœ… Beautiful Web UI
âœ… 4 AI Models (OpenAI, Anthropic, Google, Ollama)
âœ… Real-time Chat
âœ… Auto-save History
âœ… Temperature Controls
âœ… Token Management
âœ… Dark/Light Theme
âœ… Mobile Responsive
âœ… API Documentation
âœ… Production Ready

---

## ğŸ“ Common Tasks

### Send a Chat Message
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}],
    "model": "openai"
  }'
```

### Get Available Models
```bash
curl http://localhost:8000/api/models
```

### Get Chat History
```bash
curl http://localhost:8000/api/memory
```

### Clear Memory
```bash
curl -X DELETE http://localhost:8000/api/memory
```

---

## ğŸš¢ Deploy to Production

### Local Server
```bash
python main.py
```

### Production Server
```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app
```

### Docker
```bash
docker build -t ai-assistant .
docker run -p 8000:8000 ai-assistant
```

### Environment Setup for Production
```bash
# Use production settings
API_DEBUG=false
API_HOST=0.0.0.0
API_PORT=8000

# Add authentication
# Add HTTPS
# Add rate limiting
# Add monitoring
```

---

## ğŸ“Š Project Overview

```
Your Project
â”œâ”€â”€ Backend API (FastAPI)
â”‚   â”œâ”€â”€ OpenAI Support
â”‚   â”œâ”€â”€ Anthropic Support
â”‚   â”œâ”€â”€ Google Support
â”‚   â””â”€â”€ Ollama Support (Free!)
â”œâ”€â”€ Web UI (HTML/CSS/JS)
â”‚   â”œâ”€â”€ Chat Interface
â”‚   â”œâ”€â”€ Model Selector
â”‚   â””â”€â”€ Settings Panel
â”œâ”€â”€ Conversation Memory
â”‚   â”œâ”€â”€ Browser Storage
â”‚   â””â”€â”€ Server JSON Storage
â””â”€â”€ Complete Documentation
    â”œâ”€â”€ API Guide
    â”œâ”€â”€ Architecture
    â””â”€â”€ Setup Instructions
```

---

## ğŸ¯ Success Checklist

- [ ] Server running: `python main.py`
- [ ] Web UI opens: `http://localhost:8000`
- [ ] Can type messages
- [ ] Can select different models
- [ ] Response appears in chat
- [ ] Chat history saves
- [ ] API docs work: `http://localhost:8000/docs`

**If all checked: âœ… You're ready to go!**

---

## ğŸ†˜ Get Help

1. **Check the docs** - Most answers are in README.md
2. **Run verify_setup.py** - Checks if everything is configured correctly
3. **Check server output** - Error messages are logged
4. **Read API docs** - Visit `/docs` endpoint
5. **Review examples** - Check test_api.py for examples

---

## ğŸ‰ Congratulations!

You now have a **complete, production-ready AI assistant** with:
- âœ… Backend API
- âœ… Web interface
- âœ… Multiple AI models
- âœ… Conversation memory
- âœ… Full documentation

**Start building something amazing! ğŸš€**

---

**Quick Links:**
- ğŸ“– [README.md](README.md) - Full documentation
- ğŸ”Œ [API_USAGE_GUIDE.md](API_USAGE_GUIDE.md) - API reference
- ğŸ—ï¸ [ARCHITECTURE.md](ARCHITECTURE.md) - System design
- ğŸ“‹ [MANIFEST.md](MANIFEST.md) - File listing
- ğŸ“Š [FINAL_SUMMARY.md](FINAL_SUMMARY.md) - Complete summary

**Server Command:** `python main.py`
**Browser URL:** `http://localhost:8000`
**API Docs:** `http://localhost:8000/docs`
